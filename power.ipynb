{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch\n",
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_E7VGydsDmm",
        "outputId": "0b25006e-6b64-4b6b-b4fc-7084365789b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.5.1+cu124\n",
            "Uninstalling torch-2.5.1+cu124:\n",
            "  Successfully uninstalled torch-2.5.1+cu124\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "MaXlYPqzsUB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transformation = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose([transforms.RandomCrop(size=32, padding=4),\n",
        "                                                                                    transforms.RandomHorizontalFlip(), transformation]))\n",
        "\n",
        "train_dataset_fast = CIFAR10(root='./data', train=True, download=True,transform=transformation)\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transformation)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=2)\n",
        "train_loader_fast = DataLoader(train_dataset_fast, batch_size=1000, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfRB5qFipSBW",
        "outputId": "4632e973-cfe8-4d10-e549-f8a2334edfc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "          nn.Conv2d(3, 5, 5),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "          nn.Conv2d(5, 5, 5),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2, 2),\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(125, 30),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(30, 10),\n",
        "          )\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "        self.scheduler = StepLR(self.optimizer, step_size=4, gamma=0.1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "       return self.model(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "LlJQUoz6Zx79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(epochs, acc, lss):\n",
        "\n",
        "  fig, ax1 = plt.subplots()\n",
        "  plt.plot(range(1, epochs + 1), lss, marker='o', color='tab:blue', label='Loss')\n",
        "  ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "  # Create a second y-axis to plot accuracy\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.set_ylabel('Accuracy (%)', color='tab:orange')\n",
        "  ax2.plot(range(1, epochs + 1), acc, marker='x', color='tab:orange', label='Accuracy')\n",
        "  ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.title('Epoch vs Loss and Accuracy')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "kGG3I-Nds1OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqyB87PMYbR2"
      },
      "outputs": [],
      "source": [
        "def train_model(model, epochs, trainloader, testloader , device):\n",
        "\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  model.to(device)\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    right,total  = 0, 0\n",
        "\n",
        "    train_total_loss = 0\n",
        "\n",
        "    train_right,train_total  = 0, 0\n",
        "\n",
        "    model.optimizer.zero_grad()\n",
        "    model.train()\n",
        "    print(\"STARTING LOADER\" + \"=\"*70)\n",
        "    for X_batch, y_batch in trainloader:\n",
        "      #print(\"TEAT: \" + '-'*80)\n",
        "\n",
        "\n",
        "      # print(X_batch.shape)\n",
        "\n",
        "      outputs = model.forward(X_batch.to(device))\n",
        "      #print(\"OUTPUT: \" '-'*80)\n",
        "      #print(outputs[0])\n",
        "\n",
        "      #print(outputs[0])\n",
        "      # print(\"CALCULATING LOSS\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # print(f\"exp: {y_batch.shape}.   , actual: {outputs.shape}\")\n",
        "      # print(f\"type: {type(y_batch[0])},       type: {type(outputs[0])}\")\n",
        "\n",
        "      # print(f\"type: {type(y_batch)},       type: {type(outputs)}\")\n",
        "\n",
        "      # print(outputs[0])\n",
        "\n",
        "\n",
        "      loss = model.loss(outputs.to(device), y_batch.to(device))\n",
        "\n",
        "      pred = torch.argmax(outputs, dim=1)\n",
        "\n",
        "      train_right += (pred == y_batch.to(device)).sum()\n",
        "      train_total += len(y_batch)\n",
        "\n",
        "\n",
        "      train_total_loss += loss\n",
        "\n",
        "      #print(\"GOING BACKWARDS\")\n",
        "      loss.backward()\n",
        "      model.optimizer.step()\n",
        "      model.optimizer.zero_grad()\n",
        "      #print(\"BACKWARD DONE\")\n",
        "    #model.scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_total_loss}, Train Accuracy: {train_right/train_total}\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      print(\"STARTING TEST LOADER\")\n",
        "      for X_batch_test, y_batch_test in testloader:\n",
        "\n",
        "\n",
        "        outputs_test = model.forward(X_batch_test.to(device))\n",
        "\n",
        "\n",
        "        pred = torch.argmax(outputs_test, dim=1)\n",
        "        loss = model.loss(outputs_test, y_batch_test.to(device))\n",
        "\n",
        "        right += (pred == y_batch_test.to(device)).sum()\n",
        "        total += len(y_batch_test)\n",
        "\n",
        "        total_loss += loss\n",
        "\n",
        "    losses.append(loss.to(torch.device('cpu')).detach().numpy())\n",
        "    accuracies.append((right/total).to(torch.device('cpu')).detach().numpy())\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Test Loss: {total_loss}, Test Accuracy: {right/total}\")\n",
        "\n",
        "  print(type(loss))\n",
        "\n",
        "  plot_results(epochs, accuracies, losses)\n",
        "  return losses, accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kPiOhdLGtIfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLQgmGrVhwtR"
      },
      "outputs": [],
      "source": [
        "def train_modeltwo(model, epochs, trainloader, testloader , device):\n",
        "\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  model.to(device)\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    right,total  = 0, 0\n",
        "\n",
        "    train_total_loss = 0\n",
        "\n",
        "    train_right,train_total  = 0, 0\n",
        "\n",
        "    model.optimizer.zero_grad()\n",
        "    model.train()\n",
        "    print(\"STARTING LOADER\" + \"=\"*70)\n",
        "    for X_batch, y_batch in trainloader:\n",
        "      #print(\"TEAT: \" + '-'*80)\n",
        "\n",
        "\n",
        "      # print(X_batch.shape)\n",
        "\n",
        "      outputs = model.forward(X_batch.to(device))\n",
        "      #print(\"OUTPUT: \" '-'*80)\n",
        "      #print(outputs[0])\n",
        "\n",
        "      #print(outputs[0])\n",
        "      # print(\"CALCULATING LOSS\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # print(f\"exp: {y_batch.shape}.   , actual: {outputs.shape}\")\n",
        "      # print(f\"type: {type(y_batch[0])},       type: {type(outputs[0])}\")\n",
        "\n",
        "      # print(f\"type: {type(y_batch)},       type: {type(outputs)}\")\n",
        "\n",
        "      # print(outputs[0])\n",
        "\n",
        "\n",
        "      loss = model.loss(outputs.to(device), y_batch.to(device))\n",
        "\n",
        "      pred = torch.argmax(outputs, dim=1)\n",
        "\n",
        "      train_right += (pred == y_batch.to(device)).sum()\n",
        "      train_total += len(y_batch)\n",
        "\n",
        "\n",
        "      train_total_loss += loss\n",
        "\n",
        "      #print(\"GOING BACKWARDS\")\n",
        "      loss.backward()\n",
        "      model.optimizer.step()\n",
        "      model.optimizer.zero_grad()\n",
        "      #print(\"BACKWARD DONE\")\n",
        "    #model.scheduler.step()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_total_loss}, Train Accuracy: {train_right/train_total}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "md = ConvNet()\n",
        "new_md = train_modeltwo(md, 2, train_loader, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLW9sFeKtNMx",
        "outputId": "5e8e35c0-6996-4f7d-80af-e9cdb8a08864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING LOADER======================================================================\n",
            "Epoch 1/2, Train Loss: 950.27001953125, Train Accuracy: 0.28459998965263367\n",
            "STARTING LOADER======================================================================\n",
            "Epoch 2/2, Train Loss: 820.862060546875, Train Accuracy: 0.3854199945926666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_md.eval()\n",
        "\n",
        "\n",
        "\n",
        "for X_fast, y_fast in train_loader_fast:\n",
        "  loss = new_md.loss(new_md(X_fast.to(device)), y_fast.to(device))\n",
        "\n",
        "\n",
        "  g = torch.autograd.grad(loss, new_md.parameters(), create_graph=True)\n",
        "  break"
      ],
      "metadata": {
        "id": "hwuF2NsOi-NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g"
      ],
      "metadata": {
        "id": "u9phncLgEwCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for grad in g:\n",
        "#   flt = grad.flatten()\n",
        "#   for flt_item in flt:\n",
        "#     hes = torch.autograd.grad(flt_item, new_md.parameters(), retain_graph=True)\n",
        "#     print(f\"hessian shape: {hes}\")\n",
        "\n",
        "flattened_g = torch.cat([grad.view(-1) for grad in g])\n",
        "print(flattened_g.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URnSyliIic8T",
        "outputId": "f07d211a-91e8-472d-d3bf-ff7ad1063a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hessian = []\n",
        "\n",
        "for g in flattened_g:\n",
        "        hessian_row = torch.autograd.grad(g, new_md.parameters(), retain_graph=True)\n",
        "        hessian.append(torch.cat([hr.reshape(-1) for hr in hessian_row]))\n",
        "\n",
        "hessian_matrix = torch.stack(hessian)"
      ],
      "metadata": {
        "id": "jvZkikgrFjtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "eigenvalues, _ = torch.linalg.eig(hessian_matrix)"
      ],
      "metadata": {
        "id": "NRFj9z0pIVfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvalues = eigenvalues.real\n",
        "\n",
        "# Get 5 smallest and 5 largest eigenvalues\n",
        "eigenvalues = torch.sort(eigenvalues).values"
      ],
      "metadata": {
        "id": "z2TG6uf3PBnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenvalues.cpu().detach()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_xyRrslPDV8",
        "outputId": "afba46b3-eba2-4b94-85b1-124824a7fd40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9763, -0.9377, -0.8863,  ..., 25.2600, 32.3954, 50.5742])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"five largest eignevalues: {eigenvalues[-5:].cpu().detach().tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrZN5yiQKbyo",
        "outputId": "e55ef017-d144-4604-c2b7-770dfc2126ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "five largest eignevalues: [14.031505584716797, 17.89615821838379, 25.25998878479004, 32.3953857421875, 50.57416915893555]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"five smallests eignevalues: {eigenvalues[:5].cpu().detach().tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmw11Z2IIQWt",
        "outputId": "e6b8f2fe-0b5e-45d1-a36c-b08b3dabe81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "five smallests eignevalues: [-0.9762833714485168, -0.9376521110534668, -0.886317789554596, -0.8202689290046692, -0.7870007753372192]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def power_method(model, loader, iterations=50, beta=0.9, lss = None):\n",
        "    model.eval()\n",
        "    images, labels = next(iter(loader))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    v = torch.randn(sum(p.numel() for p in model.parameters())).to(device)  # Random init\n",
        "    v /= torch.norm(v)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        loss = lss(model(images), labels) if lss is not None  else model.loss(model(images), labels)\n",
        "        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "        grads = torch.cat([g.view(-1) for g in grads])\n",
        "\n",
        "        u = torch.autograd.grad(grads @ v, model.parameters(), retain_graph=True)\n",
        "        u = torch.cat([ui.reshape(-1) for ui in u])\n",
        "\n",
        "        u_norm = torch.norm(u)\n",
        "        v = beta * v + (1 - beta) * u / u_norm\n",
        "        v /= torch.norm(v)\n",
        "\n",
        "        eigenvalue = (v @ u).item()\n",
        "        #print(f\"Iteration {i+1}: Eigenvalue Estimate = {eigenvalue}\")\n",
        "\n",
        "    return eigenvalue\n",
        "\n",
        "largest_eigenvalue = power_method(new_md, train_loader_fast)\n",
        "print(\"Largest Eigenvalue from Power Method:\", largest_eigenvalue)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eskcffGkDQk",
        "outputId": "bbdd05fb-3ceb-432d-febc-ae8ffdc8cbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest Eigenvalue from Power Method: 47.05564880371094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "resnet_model = resnet50().to(device)\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "before_iter = power_method(resnet_model, train_loader_fast, lss = criterion)\n",
        "print(\"Eigenvalue Before Training:\", before_iter)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    resnet_model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Compute largest eigenvalue after 10 epochs\n",
        "after_10 = power_method(resnet_model, train_loader_fast, lss = criterion)\n",
        "print(\"Eigenvalue After 10 Epochs:\", after_10)\n",
        "\n",
        "# Continue training for 90 more epochs (total 100)\n",
        "for epoch in range(90):\n",
        "    resnet_model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "after_100 = power_method(resnet_model, train_loader_fast, lss = criterion)\n",
        "\n",
        "# Compute largest eigenvalue after 100 epochs\n",
        "print(\"Eigenvalue After 100 Epochs:\", after_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMXHvH-AuTRb",
        "outputId": "9078f630-4cfe-43e6-c0c9-db13e39037ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalue Before Training: 5312.294921875\n",
            "Eigenvalue After 10 Epochs: 151.6533203125\n",
            "Eigenvalue After 100 Epochs: 254.95614624023438\n"
          ]
        }
      ]
    }
  ]
}